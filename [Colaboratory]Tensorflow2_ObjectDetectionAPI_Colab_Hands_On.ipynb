{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Colaboratory]Tensorflow2-ObjectDetectionAPI-Colab-Hands-On.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUCNWeZ2wBFp",
        "colab_type": "text"
      },
      "source": [
        "# <b>[Colaboratory]Tensorflow2-ObjectDetectionAPI-Colab-Hands-On.ipynb</b><br>\n",
        "[Tensorflow2-ObjectDetectionAPI-Colab-Hands-On](https://github.com/Kazuhito00/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On)\n",
        "\n",
        "---\n",
        "このノートブックはTensorflow2 Object Detection APIの学習/推論のハンズオン用スクリプトです。<br>\n",
        "Colaboratoryのハードウェア アクセラレータ設定をGPUにして実行してください。<br>\n",
        "\n",
        "---\n",
        "This notebook is a hands-on script for learning/inference of the Tensorflow2 Object Detection API.<br>\n",
        "Set the hardware accelerator setting of Colaboratory to GPU and execute it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr36a9P3whVQ",
        "colab_type": "text"
      },
      "source": [
        "# <b>Google Driveマウント(checkpoint、saved model格納先)</b>\n",
        "Google Drive mount(checkpoint, saved model storage location)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdjNWM8HwitO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FATF4iQ4ANdF",
        "colab_type": "text"
      },
      "source": [
        "# <b>Tensorflow Object Detection API設定</b>\n",
        "Set Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpgBfSdZAT82",
        "colab_type": "text"
      },
      "source": [
        "### Protocol Buffers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvMZTXVbARNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -OL https://github.com/google/protobuf/releases/download/v3.2.0/protoc-3.2.0-linux-x86_64.zip\n",
        "!unzip protoc-3.2.0-linux-x86_64.zip -d protoc3\n",
        "!sudo mv protoc3/bin/* /usr/local/bin/\n",
        "!sudo mv protoc3/include/* /usr/local/include/\n",
        "!rm -rf protoc3 protoc-3.2.0-linux-x86_64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80tsIvjRAV6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "%cd /content/models/research\n",
        "\n",
        "!/usr/local/bin/protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFkjFNTGAcaT",
        "colab_type": "text"
      },
      "source": [
        "### 必要ライブラリインストール\n",
        "Installation of required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nem-gkjuAV_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/models/research/object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7LjWeQFAV3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# インストール成否確認(Confirmation of successful installation)\n",
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9_s3CAtzKFI",
        "colab_type": "text"
      },
      "source": [
        "# <b>Tensorflow2-ObjectDetectionAPI-Colab-Hands-Onリポジトリクローン</b>\n",
        "Clone Tensorflow2-ObjectDetectionAPI-Colab-Hands-On repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg73roLzzVyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Kazuhito00/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kfwGjF4kols",
        "colab_type": "text"
      },
      "source": [
        "# <b>TFRecordをアップロードする</b>\n",
        "Upload TF Record\n",
        "\n",
        "---\n",
        "「Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/02_tfrecord」に<br>VoTTからエクスポートしたTFRecordを格納してください。\n",
        "\n",
        "---\n",
        "\n",
        "Please store the TFRecord exported from VoTT <br> in \"Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/02_tfrecord\".\n",
        "<br><br>\n",
        "![](https://user-images.githubusercontent.com/37477845/94039064-31f8cc80-fe02-11ea-81f2-28427d759099.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08ZcM9-Bw8Xy",
        "colab_type": "text"
      },
      "source": [
        "# <b>学習データ/検証データ 分割</b>\n",
        "Split Training data/validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g-2VP8j6bgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_data_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/02_tfrecord'\n",
        "train_data_dir = '/content/models/research/train_data'\n",
        "val_data_dir = '/content/models/research/val_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7NoOeHkwk_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ディレクトリ作成(Create a directory)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree(train_data_dir, ignore_errors=True)\n",
        "shutil.rmtree(val_data_dir, ignore_errors=True)\n",
        "os.mkdir(train_data_dir)\n",
        "os.mkdir(val_data_dir)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XAfNhTVjUes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "# ファイル数カウント(Count the number of files)\n",
        "file_count = len(glob.glob(original_data_dir + '/*.tfrecord'))\n",
        "print('File count : ' + str(file_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxJk4E1P11pT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# 学習データ/検証データ 分割(Split Training data/validation data.)\n",
        "train_ratio = 0.75\n",
        "\n",
        "file_list = glob.glob(original_data_dir + '/*.tfrecord')\n",
        "random_sample_list = random.sample(file_list, file_count)\n",
        "\n",
        "# ディレクトリへコピー(Copy to directory)\n",
        "for index, filepath in enumerate(random_sample_list):\n",
        "    if index < int(file_count * train_ratio):\n",
        "        # 学習データ(Training data)\n",
        "        shutil.copy2(filepath, train_data_dir)\n",
        "    else:\n",
        "        # 検証データ(Validation data)\n",
        "        shutil.copy2(filepath, val_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A-UvwHC7hLW",
        "colab_type": "text"
      },
      "source": [
        "# <b>学習済モデル</b>\n",
        "Pre-Trained model\n",
        "\n",
        "---\n",
        "このハンズオンでは「Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model」に<br>学習済モデル(EfficientDet-D0)が格納してあります。<br><br>学習済モデル取得元：http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz\n",
        "\n",
        "---\n",
        "In this hands-on, the pre-trained model(EfficientDet-D0) is stored in \"Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model\".\n",
        "<br><br>\n",
        "Pre-Trained model acquisition source: http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORYqE_A0Bm0y",
        "colab_type": "text"
      },
      "source": [
        "# <b>モデル訓練</b>\n",
        "Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO6EZSbnIY-s",
        "colab_type": "text"
      },
      "source": [
        "### 保存先ディレクトリ作成(Googleドライブ)\n",
        "Create a directory(Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-ElsZLHxHvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir '/content/gdrive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_7GvE2KIbMk",
        "colab_type": "text"
      },
      "source": [
        "### TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctvO4SJD11u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-M__9iNHK80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir '/content/gdrive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_bm5VtPk4SO",
        "colab_type": "text"
      },
      "source": [
        "# <b>パイプラインコンフィグアップロード</b>\n",
        "Pipeline config upload\n",
        "\n",
        "---\n",
        "パイプラインコンフィグを修正し「Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model」にアップロードしてください。<br><br>\n",
        "パイプラインコンフィグは以下の行を修正します。<br>\n",
        "\n",
        "---\n",
        "Please modify the pipeline config and upload it to \"Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model\".<br><br>\n",
        "Pipeline Config modifies the following line.\n",
        "\n",
        "---\n",
        "\n",
        "* 3行目：クラス数<br>num_classes: 90 → 1<br>\n",
        "* 134行目：バッチサイズ<br>batch_size: 128 → 16<br>\n",
        "* 161行目：ファインチューニング用のチェックポイント格納先<br>fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\" → \"/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\n",
        "* 167行目：ファインチューニング方法<br>fine_tune_checkpoint_type: \"classification\" → \"detection\"<br>\n",
        "168行目：Googleカスタム 16ビットbrain浮動小数点の使用有無<br>use_bfloat16: true → false<br>\n",
        "* 172行目：ラベルマップファイルの格納先<br>label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\" → \"/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/02_tfrecord/tf_label_map.pbtxt\"<br>\n",
        "* 174行目：学習データの格納先<br>input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\" → \"/content/models/research/train_data/??????.tfrecord\"<br>\n",
        "* 185行目：ラベルマップファイルの格納先<br>label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\" → \"/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/02_tfrecord/tf_label_map.pbtxt\"<br>\n",
        "* 189行目：バリデーションデータの格納先<br>input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\" → \"/content/models/research/val_data/??????.tfrecord\"\n",
        "<br><br>\n",
        "![](https://user-images.githubusercontent.com/37477845/94040113-83558b80-fe03-11ea-8d8a-a5304efcca1d.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpEgC85TIeVR",
        "colab_type": "text"
      },
      "source": [
        "# <b>学習</b>\n",
        "Training<br>\n",
        "\n",
        "---\n",
        "\n",
        "学習はColaboratory上で1000ステップにつき、約25分かかります。\n",
        "\n",
        "---\n",
        "Learning takes about 25 minutes per 1000 steps on the Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLOMjRA28IHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=\"/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model/pipeline.config\" \\\n",
        "    --model_dir=\"/content/gdrive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On\" \\\n",
        "    --num_train_steps=1000 \\\n",
        "    --alsologtostderr \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0ZTEuHAnMxp",
        "colab_type": "text"
      },
      "source": [
        "# <b>saved model形式へエクスポート</b>\n",
        "Export to saved-model format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuL08MMmIBzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python object_detection/exporter_main_v2.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=\"/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model/pipeline.config\" \\\n",
        "    --trained_checkpoint_dir=\"/content/gdrive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On\" \\\n",
        "    --output_directory=\"/content/gdrive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/output\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB6Z34Wcs6NW",
        "colab_type": "text"
      },
      "source": [
        "# <b>モデルロード</b>\n",
        "Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUaigXpntNVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_path = '/content/gdrive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/output/saved_model'\n",
        "\n",
        "DEFAULT_FUNCTION_KEY = 'serving_default'\n",
        "loaded_model = tf.saved_model.load(model_path)\n",
        "inference_func = loaded_model.signatures[DEFAULT_FUNCTION_KEY]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtKvTGJXLBZE",
        "colab_type": "text"
      },
      "source": [
        "# <b>推論</b>\n",
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VHkShurKtVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 推論対象のテスト画像一覧(List of test images to be inferred)\n",
        "import glob\n",
        "import copy\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "test_data_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data'\n",
        "testfile_list = sorted(glob.glob(test_data_dir + '/*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEIBDIeRpswu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 推論用関数(Function for inference)\n",
        "def run_inference_single_image(image, inference_func):\n",
        "    tensor = tf.convert_to_tensor(image)\n",
        "    output = inference_func(tensor)\n",
        "\n",
        "    output['num_detections'] = int(output['num_detections'][0])\n",
        "    output['detection_classes'] = output['detection_classes'][0].numpy()\n",
        "    output['detection_boxes'] = output['detection_boxes'][0].numpy()\n",
        "    output['detection_scores'] = output['detection_scores'][0].numpy()\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPdZ-PLMLZeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "filenames = []\n",
        "\n",
        "# 動画書き出し用設定(VideoWriter setting)\n",
        "temp_image = cv2.imread(testfile_list[0], cv2.IMREAD_UNCHANGED)\n",
        "image_width, image_height = temp_image.shape[1], temp_image.shape[0]\n",
        "fourcc = 'mp4v'\n",
        "writer_fourcc = cv2.VideoWriter_fourcc(*fourcc)\n",
        "videowriter = cv2.VideoWriter('result.mp4', writer_fourcc, 10, (image_width, image_height))\n",
        "\n",
        "# 推論(Inference)\n",
        "for filecount, testfile in enumerate(testfile_list):\n",
        "    image = cv2.imread(testfile, cv2.IMREAD_UNCHANGED)\n",
        "    debug_image = copy.deepcopy(image)\n",
        "\n",
        "    image_width, image_height = image.shape[1], image.shape[0]\n",
        "    image = image[:, :, [2, 1, 0]]  # BGR2RGB\n",
        "    image_np_expanded = np.expand_dims(image, axis=0)\n",
        "\n",
        "    output = run_inference_single_image(image_np_expanded, inference_func)\n",
        "\n",
        "    num_detections = output['num_detections']\n",
        "    for i in range(num_detections):\n",
        "        score = output['detection_scores'][i]\n",
        "        bbox = output['detection_boxes'][i]\n",
        "        # class_id = output['detection_classes'][i].astype(np.int)\n",
        "\n",
        "        if score < 0.85:\n",
        "            continue\n",
        "\n",
        "        x1, y1 = int(bbox[1] * image_width), int(bbox[0] * image_height)\n",
        "        x2, y2 = int(bbox[3] * image_width), int(bbox[2] * image_height)\n",
        "\n",
        "        # 推論結果描画(Inference result drawing)\n",
        "        cv2.rectangle(debug_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
        "        cv2.putText(debug_image, str('{:.2f}'.format(score)), (x1, y1-10), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "        cv2.rectangle(debug_image, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
        "    videowriter.write(debug_image)\n",
        "videowriter.release()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXJBbDNYxnp0",
        "colab_type": "text"
      },
      "source": [
        "# <b>推論結果確認</b>\n",
        "Inference result confirmation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9kmLlk0-TPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "def play_video(video, interval=100):\n",
        "    video = imageio.mimread(video)\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "    movie = []\n",
        "    for i in range(len(video)):\n",
        "        img = plt.imshow(video[i], animated=True)\n",
        "        plt.axis('off')\n",
        "        movie.append([img])\n",
        "\n",
        "    anime = animation.ArtistAnimation(fig, movie, interval=interval, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return anime\n",
        "\n",
        "HTML(play_video('result.mp4').to_html5_video()) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}